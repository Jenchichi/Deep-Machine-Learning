{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Visualiseringslabb - Feature Attribution & Visualization\n",
    "\n",
    "## Introduction\n",
    "Denna notebook utforskar convolutional neural networks (CNNs) genom visualisering av deras inre arbetssätt. Vi kommer att undersöka:\n",
    "- Feature attribution med CAM (Class Attribution Map)\n",
    "- Visualization av aktiveringar i olika lager\n",
    "- Hur nätverket \"ser\" och tolkar bilder\n",
    "\n",
    "**Mål för betyg G:**\n",
    "- Visualisera minst två lager\n",
    "- Testa på minst två bilder\n",
    "- Använda torch-cam för attribution\n",
    "\n",
    "**Mål för betyg VG:**\n",
    "- Allt från G + gradient ascent implementation\n",
    "- Activation maximization\n",
    "- Fördjupad analys av filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import och Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importera nödvändiga bibliotek\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# För CAM visualisering\n",
    "from torchcam.methods import CAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "# Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Använder device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ladda Förtränad Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ladda förtränad VGG16 modell\n",
    "model = models.vgg16(pretrained=True)\n",
    "model = model.to(device)\n",
    "model.eval()  # Sätt till evalueringsläge\n",
    "\n",
    "print(\"VGG16 modell laddad!\")\n",
    "print(\"Modellstruktur:\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bildförberedelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiera transforms för bilder\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Funktion för att ladda och preprocessa bild\n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    return image, input_tensor\n",
    "\n",
    "# Funktion för att visa bild\n",
    "def show_image(image, title=\"Bild\"):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        # Konvertera från tensor till numpy\n",
    "        image = image.cpu().squeeze().permute(1, 2, 0).numpy()\n",
    "        # Un-normalize\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = image * std + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Bildfunktioner redo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ladda Testbilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sökvägar till testbilder\n",
    "image_paths = [\n",
    "    \"images/Chicko.jpg\",\n",
    "    \"images/Idun.jpg\"\n",
    "]\n",
    "\n",
    "# Skapa mapp för bilder om den inte finns\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "# Ladda bilder (om de finns)\n",
    "images = []\n",
    "input_tensors = []\n",
    "\n",
    "for path in image_paths:\n",
    "    if os.path.exists(path):\n",
    "        img, tensor = load_and_preprocess_image(path)\n",
    "        images.append(img)\n",
    "        input_tensors.append(tensor)\n",
    "        print(f\"Laddade bild: {path}\")\n",
    "    else:\n",
    "        print(f\"Varning: Bilden {path} hittades inte\")\n",
    "\n",
    "# Visa laddade bilder\n",
    "for i, img in enumerate(images):\n",
    "    show_image(img, f\"Testbild {i+1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CAM Visualisering - Förberedelse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion för att skapa och visa CAM\n",
    "def visualize_cam(model, input_tensor, target_layer, class_idx=None):\n",
    "    \"\"\"\n",
    "    Visualisera Class Activation Map för ett specifikt lager\n",
    "    \"\"\"\n",
    "    # Skapa CAM extraktor\n",
    "    cam_extractor = CAM(model, target_layer=target_layer)\n",
    "    \n",
    "    # Få prediction från modellen\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax().item()\n",
    "    \n",
    "    print(f\"Predicerad klass: {class_idx} (confidence: {torch.softmax(output, dim=1)[0, class_idx]:.4f})\")\n",
    "    \n",
    "    # Extrahera CAM\n",
    "    activation_map = cam_extractor(class_idx, output)\n",
    "    \n",
    "    # Konvertera till numpy och overlay på originalbild\n",
    "    result = overlay_mask(images[0], activation_map[0].squeeze(), alpha=0.5)\n",
    "    \n",
    "    # Visa resultat\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(images[0])\n",
    "    plt.title(\"Originalbild\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(activation_map[0].squeeze(), cmap='jet')\n",
    "    plt.title(f\"CAM - {target_layer}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(result)\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return activation_map\n",
    "\n",
    "print(\"CAM funktion redo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualisera Lager (G-krav)\n",
    "\n",
    "Här visualiserar vi två olika lager i VGG16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Välj två lager att visualisera\n",
    "# VGG16 har följande structure: features (conv-lager) och classifier (fc-lager)\n",
    "\n",
    "# Lager 1: Ett tidigt conv-lager (features.14 är conv3_2 i VGG16)\n",
    "layer1 = \"features.14\"\n",
    "\n",
    "# Lager 2: Ett djupare conv-lager (features.28 är conv5_1 i VGG16)\n",
    "layer2 = \"features.28\"\n",
    "\n",
    "print(f\"Visualiserar lager: {layer1} och {layer2}\")\n",
    "\n",
    "# Visualisera för första bilden (om den finns)\n",
    "if len(input_tensors) > 0:\n",
    "    print(\"\\n=== Visualisering för första bilden ===\")\n",
    "    print(f\"\\nLager 1: {layer1}\")\n",
    "    cam1 = visualize_cam(model, input_tensors[0], layer1)\n",
    "    \n",
    "    print(f\"\\nLager 2: {layer2}\")\n",
    "    cam2 = visualize_cam(model, input_tensors[0], layer2)\n",
    "else:\n",
    "    print(\"Inga bilder laddade - lägg till bilder i images-mappen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualisera för Andra Bilden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisera för andra bilden (om den finns)\n",
    "if len(input_tensors) > 1:\n",
    "    print(\"\\n=== Visualisering för andra bilden ===\")\n",
    "    print(f\"\\nLager 1: {layer1}\")\n",
    "    cam1_bild2 = visualize_cam(model, input_tensors[1], layer1)\n",
    "    \n",
    "    print(f\"\\nLager 2: {layer2}\")\n",
    "    cam2_bild2 = visualize_cam(model, input_tensors[1], layer2)\n",
    "else:\n",
    "    print(\"Endast en bild tillgänglig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analys och Resultat\n",
    "\n",
    "### Motivering av valda lager:\n",
    "1. **features.14 (conv3_2)**: Ett medeldjupt lager som fångar mellanliggande features som kanter, texturer och enkla former.\n",
    "2. **features.28 (conv5_1)**: Ett djupt lager som fångar mer abstrakta features och objektdelar.\n",
    "\n",
    "### Observationer:\n",
    "- Tidiga lager fokuserar på enkla mönster\n",
    "- Djupare lager fokuserar på mer komplexa och semantiska features\n",
    "- CAM visar vilka delar av bilden som är viktigast för klassificeringen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Slutsats\n",
    "\n",
    "Denna visualisering visar hur CNNs bygger upp en hierarki av features från enkla till komplexa. CAM-tekniken hjälper oss att förstå varför modellen fattar visst beslut genom att highlighta viktiga regioner i bilden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
